{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vlwWYFCd8Yc"
   },
   "source": [
    "# Padding and strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbkMfwklExAp"
   },
   "source": [
    "### Padding\n",
    "**In CNNs padding refers to the process of adding extra pixels (usually zeros) around the border of an input image or feature map. This is done before applying the convolution operation to control the spatial dimensions of the output feature map.**\n",
    "\n",
    "### Advatages :\n",
    "1. **Preservation of Spatial Dimensions:** Padding allows the output feature map to have the same spatial dimensions as the input, which is useful in architectures where the input and output sizes need to match.\n",
    "2. **Information Retention at Borders:** Without padding, the convolution operation reduces the size of the feature map, potentially losing important information at the borders. Padding helps mitigate this loss.\n",
    "3. **Support for Deeper Networks:** By preserving dimensions, padding supports deeper network architectures where multiple convolutions are stacked, preventing excessive shrinking of feature maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PwYVIaKExAq"
   },
   "source": [
    "## Types of padding :\n",
    "\n",
    "### Valid Padding (No Padding):\n",
    "\n",
    "* **Definition:** No padding is added to the input. The convolution operation is only applied where the kernel fits entirely within the input.\n",
    "* **Output Size:** The output size is smaller than the input size.\n",
    "* **Use Case:** When reducing the spatial dimensions is acceptable or desired.\n",
    "\n",
    "### Same Padding (Zero Padding):\n",
    "\n",
    "* **Definition:** Padding is added to the input such that the output size matches the input size. Typically, zeros are added around the border.\n",
    "* **Output Size:** The output size is the same as the input size.\n",
    "* **Use Case:** When preserving the spatial dimensions of the input is important, such as in fully convolutional networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U-NsX_qDJLPa"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense,Conv2D,Flatten\n",
    "from keras import Sequential\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xClrCioELZP_",
    "outputId": "d7333f5d-33da-4007-e662-a08218429542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywuXCH0LHdKX"
   },
   "source": [
    "# Valid Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L4lmz9UtLw-v"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu'))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWy2SujmMobQ",
    "outputId": "331f14b2-f04e-4f12-f658-9faecd87893c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15488)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1982592   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2002698 (7.64 MB)\n",
      "Trainable params: 2002698 (7.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "On5zM8ThFXSv"
   },
   "source": [
    "**Here we can see that The output size is smaller than the input size, Because No padding is added to the input.**\n",
    "\n",
    "* conv2d (Conv2D)             (None, 26, 26, 32)        \n",
    "                                                                 \n",
    "* conv2d_1 (Conv2D)           (None, 24, 24, 32)              \n",
    "                                                                 \n",
    "* conv2d_2 (Conv2D)           (None, 22, 22, 32)\n",
    "\n",
    "From Input size (28,28) -> (26,26) -> (24,24) -> (22,22),  \n",
    "Size is always decreased by 2 because kernel size is 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PukFhmvDHg34"
   },
   "source": [
    "# Same padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wqt7QWD-FH6G"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same', activation='relu'))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same', activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrYPt_5QFOwt",
    "outputId": "a6b6a97d-7f53-4d81-dc46-91698bbbc2b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3231498 (12.33 MB)\n",
      "Trainable params: 3231498 (12.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpqlS-r7GmFn"
   },
   "source": [
    "**Here we can see that The output size is the same as the input size, Because Padding is added to the input such that the output size matches the input size. Typically, zeros are added around the border.**\n",
    "\n",
    "* conv2d_3 (Conv2D)           (None, 28, 28, 32)               \n",
    "                                                                 \n",
    "* conv2d_4 (Conv2D)           (None, 28, 28, 32)              \n",
    "                                                                 \n",
    "* conv2d_5 (Conv2D)           (None, 28, 28, 32)\n",
    "\n",
    "From Input size (28,28) -> (28,28) -> (28,28) -> (28,28),\n",
    "\n",
    "Size is remained same because padding is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXps_274FO0M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jN3A8A9VH1Wi"
   },
   "source": [
    "# Strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6f0kGr3LH3lj"
   },
   "source": [
    "**Stride refers to the number of pixels by which the convolutional filter (kernel) moves (or \"slides\") over the input feature map. When the stride is greater than one, the filter jumps several pixels at a time, skipping some positions.**\n",
    "\n",
    "## Types:\n",
    "1. **Stride of 1:**\n",
    "  * The filter moves one pixel at a time.\n",
    "  * Provides the highest resolution output.\n",
    "2. **Stride Greater than 1:**\n",
    "  * The filter moves multiple pixels at a time.\n",
    "  * Produces a smaller output feature map.\n",
    "\n",
    "**Formula for Output Dimensions:**\n",
    "For an input of size ð‘›Ã—ð‘›, filter size ð‘“Ã—ð‘“, padding ð‘, and stride ð‘ , the output size ð‘œÃ—ð‘œ can be calculated as:\n",
    "* o = {[nâˆ’f+2p] / s} + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J5pq4EjFO3m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "i0-Cu9jrMzCy"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu'))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mL_dQ3K0M-ZL",
    "outputId": "ee827e63-e5c2-4b89-afbc-ccf862d5a727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85770 (335.04 KB)\n",
      "Trainable params: 85770 (335.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MU0cZwrJg1q"
   },
   "source": [
    "**Here you can see the change in input size From Input size (28,28) -> (14,14) -> (7,7) -> (4,4),**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujWp7GJmM_za"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
